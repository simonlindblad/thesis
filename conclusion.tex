%%% lorem.tex --- 
%% 
%% Filename: lorem.tex
%% Description: 
%% Author: Ola Leifler
%% Maintainer: 
%% Created: Wed Nov 10 09:59:23 2010 (CET)
%% Version: $Id$
%% Version: 
%% Last-Updated: Wed Nov 10 09:59:47 2010 (CET)
%%           By: Ola Leifler
%%     Update #: 2
%% URL: 
%% Keywords: 
%% Compatibility: 
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Commentary: 
%% 
%% 
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Change log:
%% 
%% 
%% RCS $Log$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Code:

\chapter{Conclusion}
\label{cha:conclusion}

This thesis was done in two parts: identifying active learning strategies that could be used to improve the labeling process, and filtering out the invalid reports.
When it comes to the evaluation of the active learning strategies, there were a few alternatives.
The ones chosen for evaluation here were the ones that were adapted for the multi-label scenario.
These were: 
\begin{itemize}
    \item Binary Version Space Minimization (BSVM)
    \item Maximum Loss Reduction with Maximum Confidence (MMC)
    \item Adaptive Active Learning (AAL)
\end{itemize}

For the first research question, the performance of the strategies can be summarized in that MMC performed worse in the early stages, while the adaptive approach worked the best during the same time.
BSVM performed approximately the same as random sampling in the beginning.
In the end, BSVM and MMC both achieved a higher accuracy and $F_1$-score than AAL, at least after 2000 samples were added.
All of the above-mentioned strategies performed better than random sampling in the long run.

To answer the second research question the distribution of labels for the labeled dataset was analyzed.
The distribution of labels was more uniform for all the strategies, compared to that of random sampling.
After 2000 labels, BSVM and MMC had a more even distribution than AAL.
While early on, MMC and the adaptive approach generated a lot more even label distribution than BSVM.
So, in various degrees during the labeling process, the different strategies all made the dataset more uniform than labeling at random.

Identifying and filtering out invalid reports was treated in the third research question.
It resulted in a rather good separation of the two categories.
Accomplishing this using only unsupervised techniques is possible, even if using them together with a supervised technique gave a better result.
But manually identifying relevant topics and classifying based on this information was clearly a working approach.
It did not achieve 100 \% accuracy, so there is room for improvement, but the separation has to be seen as successful.

The server that hosts the labeling system at Sectra does not have a lot of computing power.
Therefore, AAL was considered to be too computationally heavy.
Choosing between BSVM and MMC was not as straight forward given their different qualities.
In the end, BSVM was chosen to be integrated into the system, based on its long term performance and that it gave the SVM model better accuracy after fewer labels.

For future research, it would be interesting to look into how to further use the structure of the data in active learning strategies, besides only obtaining initial samples from clusters.
An example of this would be to find a good way to adapt the approach described by Dasgupta et al\@.~\cite{dasgupta2008hierarchical} to the multi-label case.
With their approach to binary classification, it is rather easy to define a measure to see when a cluster overwhelmingly consisting of one class.
However, if a data point can consist of any combination of labels it becomes a lot harder.
Using the full approach, including the usage of clusters to classify the points without another model, might be hard for this reason.
Researching whether or not the hierarchical clustering could aid the selection of data points, instead of both selection and classifying, might be more approachable.

Another thing that would be of interest is to vary the text representation and classification models to see how they get affected by the different strategies.
One example of this could be to use recurrent neural networks instead of SVM's, and see if the different active learning strategies affect the models differently.
For the text representation, word2vec or latent topic vectors could be used instead of bag of words to highlight different features of the text.
These methods described in this thesis should work well for other media such as images too. 
However, if other types of media were to be studied it would open up for some other techniques as well, something that could be an interesting area for future research.